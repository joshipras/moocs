{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>\n",
       "code_show=true; \n",
       "function code_toggle() {\n",
       " if (code_show){\n",
       " $('div.input').hide();\n",
       " $('#toggleButton').val('Show Code')\n",
       " } else {\n",
       " $('div.input').show();\n",
       " $('#toggleButton').val('Hide Code')\n",
       " }\n",
       " code_show = !code_show\n",
       "} \n",
       "$( document ).ready(code_toggle);\n",
       "</script>\n",
       "<form action=\"javascript:code_toggle()\"><input type=\"submit\" id = \"toggleButton\" value=\"Hide Code\"></form>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "HTML('''<script>\n",
    "code_show=true; \n",
    "function code_toggle() {\n",
    " if (code_show){\n",
    " $('div.input').hide();\n",
    " $('#toggleButton').val('Show Code')\n",
    " } else {\n",
    " $('div.input').show();\n",
    " $('#toggleButton').val('Hide Code')\n",
    " }\n",
    " code_show = !code_show\n",
    "} \n",
    "$( document ).ready(code_toggle);\n",
    "</script>\n",
    "<form action=\"javascript:code_toggle()\"><input type=\"submit\" id = \"toggleButton\" value=\"Hide Code\"></form>''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>Lesson 3: Choosing and Characterizing Metrics</center></h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How do we measure whether experiment group better than the control group or not?\n",
    "\n",
    "By defining a metric or a set of metrics. This depends on what you are going to use the metrics for. 2 main use cases include:\n",
    "\n",
    "1. <b>Invariant Checking: </b> Metrics that shouldn't change across control and experiement group\n",
    "Eg. Populations in both groups should be same, distributions should be the same.\n",
    "<br>\n",
    "2. <b>Evaluation:</b>\n",
    "<ul>\n",
    "<li> High level business metrics: Eg. How much revenue you make, how much you market share is\n",
    "<li> Detailed User Experience: \n",
    "    <ul>\n",
    "    <li>Eg 1. How long people stayed on page. \n",
    "    <li>Eg 2. If users are not finishing the course, drill down to specific parts of the funnel and check if videos taking too long (latency issues) or if assignments hard etc.\n",
    "        </ul>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to go about actually making a metric definition?\n",
    "\n",
    "\n",
    "1. Start with high level concept that is easily understood by all. Eg. Active Users/Click Through Probability.\n",
    "\n",
    "2. Figure out the nitty gritty:\n",
    "<ul>\n",
    "<li> How to define Active Users: 7 day active users, 28 day active users.\n",
    "<li> Which events count towards Active: does notification count?, etc.\n",
    "</ul>\n",
    "<br>\n",
    "3. Summarize into a single metric:\n",
    "<ul> \n",
    "<li>Sum/median/count/average/median </li>\n",
    "<li> Choice of a single metric can be tricky. <br>Org leaders need to be comfortable understanding it. <br>Also hard to tie a change back to specific reason. </li>   \n",
    "</ul>\n",
    "\n",
    "<b>Notes:</b> \n",
    "<li>It is helpful to define metrics at various stages of a funnel that are a step in the process of achieving eventual business objective (eg. At Audacity: Helping students get skilled in courses/get jobs/financial stability)\n",
    "<li> Some metrics can be difficult to measure, we can use other techniques for these.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#How to convert a high level metric into a well defined metric?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Why should you filter your data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Spam/Fraud: competitor may be clicking on everything\n",
    "- Blog coverage / traffic coming to just see the experiment: may bias results\n",
    "- Population unaffected by change: Eg. Filter out international traffic for local change, filter out desktop traffic for a mobile app change.\n",
    "- Avoid biasing data: Eg. removing long sessions of data\n",
    "- Check for bias by computing metric on slices of data that contain disjointed sets (different goelocations), daily or weekly trends to spot anything unusual.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary Metrics\n",
    "\n",
    "* Some direct data measurements (Eg. Pageview, click) are single number, can be easily summarized. Eg: How many cookies visiting the homepage can be summarised into mean/median per day/week.\n",
    "* Some direct data measurements may not be a single number, per event measurement itself is a number (Eg. Load time of a video/ How many terms are in a query) \n",
    "    - For these, observe distribution (histogram) \n",
    "    - For a normal distribution, mean/median make sense. \n",
    "    - For lopsided distributions 25th or 75th percentiles may make sense.\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Sensitivity and Robustness:\n",
    "   \n",
    "We want metrics to be\n",
    "    - Sensitive enough to pick up changes you care about\n",
    "    - Robust against changes you don't care about\n",
    "    \n",
    "    \n",
    "For example: we want to check if latency affects load times of video: mean/median?\n",
    "    - Mean sensitive to outliers: not robust\n",
    "    - Median is robust, but when considering only fraction of the data, median might be unchanged.\n",
    "            \n",
    "In a case like this consider other statistics such as 90th or 99th percentile.\n",
    "        \n",
    "        \n",
    "How to measure sensitivity and robustness?\n",
    "\n",
    "1. Run few simple experiments. <br>\n",
    "   - <b>Latency example:</b> <br>Increase quality of video,<br> which should in theory increase load times,<br>\n",
    "      see if metrics we are interested in respond to that.\n",
    "\n",
    "   - <b>A vs A experiements </b>\n",
    "      <br> to determine if metric too sensitive\n",
    "      <br>compare people who saw the same thing to each other, \n",
    "      <br>see if metric picks up spurious effects\n",
    "\n",
    "   - <b>Experiments run in the past</b> and see how metrics moved with peoples response to those.\n",
    "<br>\n",
    "\n",
    "2. Retrospective analysis of logs:<br>\n",
    "    If no prior experiement data, look at changes you made to site, see if metrics moved inconjunction with those changes.\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How to compare value for metrics between Experiment and Control groups?\n",
    "\n",
    "- simplest: absolute difference difference\n",
    "- Other: relative change (% change) only have to use 1 practical significance boundary\n",
    "    if there is seasonality or things changing with time, \n",
    "    CTR with same practical significance boundary we can have the same comparison.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variability:\n",
    "\n",
    "- When we use more difficult metrics such as percentile or median or ratio, the variance cannot be calculated analytically.\n",
    "- If data distribution not normal or if distribution not identifiable, \n",
    "    - use non-parametric methods to estimaste Confidence Interval\n",
    "    - or run A vs A tests.\n",
    "    - or bootstrap (divy up data into random small chunks) and compare within those subsets.\n",
    "- \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusions\n",
    "\n",
    "- Majority of time is spent in evaluating and validating metrics.\n",
    "    - Eg. latency hard to load across countries, devices, etc.\n",
    "    - mean latency seems robust but not very sensitive\n",
    "\n",
    "- Variability better computed analytically or empirically?\n",
    "    - Usually godd tostart with analytical characterization, get a feel for the data by looking at the distribution.\n",
    "    - With the metric like revenue for a query, in some cases it may be easier emprically than analytically.\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<hr>\n",
    "<div dir = \"rtl\">\n",
    "<ul style = 'list-style-type:square'>\n",
    "<li> End of Document\n",
    "</li>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>\n",
       "$(document).ready(function(){\n",
       "    $('div.prompt').hide();\n",
       "    $('div.back-to-top').hide();\n",
       "    $('nav#menubar').hide();\n",
       "    $('.breadcrumb').hide();\n",
       "    $('.hidden-print').hide();\n",
       " });\n",
       "</script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML('''<script>\n",
    "$(document).ready(function(){\n",
    "    $('div.prompt').hide();\n",
    "    $('div.back-to-top').hide();\n",
    "    $('nav#menubar').hide();\n",
    "    $('.breadcrumb').hide();\n",
    "    $('.hidden-print').hide();\n",
    " });\n",
    "</script>\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
